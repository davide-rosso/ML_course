{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1602683126000,
     "user": {
      "displayName": "Davide Rosso",
      "photoUrl": "",
      "userId": "18358579221259765961"
     },
     "user_tz": -120
    },
    "id": "hE0xtnAn4pja"
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First : exploring the data\n",
    "\n",
    "We'll need to have a look at what the data is, how it is distributed for the different features, and start to get an intuition about what methods might work better for analysis and prediction later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJIVugOC4pje"
   },
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "executionInfo": {
     "elapsed": 920,
     "status": "error",
     "timestamp": 1602683129008,
     "user": {
      "displayName": "Davide Rosso",
      "photoUrl": "",
      "userId": "18358579221259765961"
     },
     "user_tz": -120
    },
    "id": "6ywLVx4a4pje",
    "outputId": "6c3dc9cc-eaed-41d6-b186-c5c48d1c9066"
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoPlUo5WU-CC"
   },
   "outputs": [],
   "source": [
    "# remove samples with error values\n",
    "idx_c = np.all(tX!=-999, axis=1)\n",
    "y_c = y[idx_c]\n",
    "tX_c = tX[idx_c]\n",
    "# regularize\n",
    "mean = np.mean(tX_c, axis=0)\n",
    "std = np.std(tX_c, axis=0)\n",
    "tX_c = (tX_c-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGLf-JCXU-CE"
   },
   "outputs": [],
   "source": [
    "print(\"Overall: s: \",np.sum(y==1),\", b: \",np.sum(y==-1),\" ,total:\",len(y))\n",
    "print(\"NoErrors: s: \",np.sum(y_c==1),\", b: \",np.sum(y_c==-1),\" ,total:\",len(y_c))\n",
    "for n in range(tX_c.shape[1]):\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.subplot(131)\n",
    "    plt.hist([tX_c[y_c==1,n],tX_c[y_c==-1,n]], 20, density=True, histtype='bar', stacked=True)\n",
    "    plt.legend(['s','b'])\n",
    "    plt.title('Feature '+str(n))\n",
    "    plt.subplot(132)\n",
    "    plt.title('s histogram feature '+str(n))\n",
    "    plt.hist(tX_c[y_c==1,n], 20, density=True, histtype='bar', stacked=True)\n",
    "    plt.subplot(133)\n",
    "    plt.title('b histogram feature '+str(n))\n",
    "    plt.hist(tX_c[y_c==-1,n], 20, density=True, histtype='bar', stacked=True)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove features with error values\n",
    "idx_gf = np.arange(tX.shape[1])[np.all(tX!=-999, axis=0)]\n",
    "y_gf = y\n",
    "tX_gf = tX[:,idx_gf]\n",
    "# regularize\n",
    "mean = np.mean(tX_gf, axis=0)\n",
    "std = np.std(tX_gf, axis=0)\n",
    "tX_gf = (tX_gf-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall: s: \",np.sum(y==1),\", b: \",np.sum(y==-1),\" ,total:\",len(y))\n",
    "for n in range(tX_gf.shape[1]):\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.subplot(131)\n",
    "    plt.hist([tX_gf[y_gf==1,n],tX_gf[y_gf==-1,n]], 20, density=True, histtype='bar', stacked=True)\n",
    "    plt.legend(['s','b'])\n",
    "    plt.title('Feature '+str(idx_gf[n]))\n",
    "    plt.subplot(132)\n",
    "    plt.title('s histogram feature '+str(idx_gf[n]))\n",
    "    plt.hist(tX_gf[y_gf==1,n], 20, density=True, histtype='bar', stacked=True)\n",
    "    plt.subplot(133)\n",
    "    plt.title('b histogram feature '+str(idx_gf[n]))\n",
    "    plt.hist(tX_gf[y_gf==-1,n], 20, density=True, histtype='bar', stacked=True)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5iFp9zV4pjg"
   },
   "source": [
    "# Actual predictions start from here\n",
    "\n",
    "After having looked at the data we will now do some actual predictions using different models andd parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "_ , test_X, ids_test = load_csv_data(DATA_TEST_PATH) # test y is only ? marks, so we just discard it on import with _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ql2-oUuA4ynz"
   },
   "source": [
    "## Generate predictions using only features with no errrors throughought\n",
    "\n",
    "This enables us to use some of the methods from the course directly, without having to adjust some of the functionnality to account for the fact that a lot of errors are in the dataset. First let us see which features from the test dataset are error free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import test data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test_x_df = pd.read_csv(DATA_TEST_PATH, index_col='Id').drop('Prediction', axis='columns')\n",
    "# test_y_df Not useful because already have test_y which is all good values\n",
    "\n",
    "train_x_df = pd.read_csv(DATA_TRAIN_PATH, index_col='Id').drop('Prediction', axis='columns')\n",
    "# train_y_df Not useful because we already have y which is all good values for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with -999 errors\n",
    "error_cols_te = np.full(test_x_df.shape[1], False)\n",
    "for i in range(test_x_df.shape[1]):\n",
    "#     print(test_x_df.iloc[:,i].values)\n",
    "#     print(-999.0 in test_x_df.iloc[:,i].values)\n",
    "    if -999.0 in test_x_df.iloc[:,i].values:\n",
    "        error_cols_te[i] = True\n",
    "#print(f\"There are {error_cols_te.tolist().count(True)} test error columns are which are : \\n{error_cols_te}\\n\")\n",
    "\n",
    "error_cols_tr = np.full(train_x_df.shape[1], False)\n",
    "for i in range(train_x_df.shape[1]):\n",
    "    if -999.0 in train_x_df.iloc[:,i].values:\n",
    "        error_cols_tr[i] = True\n",
    "#print(f\"There are {error_cols_tr.tolist().count(True)} train error columns are which are : \\n{error_cols_tr}\")\n",
    "\n",
    "no_error_cols_tr_te = (~(error_cols_tr | error_cols_te)).tolist()\n",
    "#print(f\"They have {no_error_cols_tr_te.count(True)} following shared non error columns :\\n{no_error_cols_tr_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this figured out we can now extract the valid columns from test and train data, do some training and testing on data, then generate answers for the test data and submit to aicrowd !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_err_train_x_df = train_x_df.T[no_error_cols_tr_te].T\n",
    "no_err_test_x_df = test_x_df.T[no_error_cols_tr_te].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_err_train_x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_err_test_x_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, note that the train y values are labeled s or b, when we actually want 1 or -1. We'll use the y_c train data imported before.\n",
    "\n",
    "### First using ridge regression\n",
    "\n",
    "For this we will need to split our train data into train/train and train/test data, to see if we start overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab3_plots import plot_train_test\n",
    "from th_helpers import build_poly, split_data, compute_rmse\n",
    "from th_ridge_regression import ridge_regression\n",
    "\n",
    "def ridge_regression_lambdas(x, y, degree, ratio, seed, lambdas=np.logspace(-5, 0, 15)):\n",
    "    \"\"\"Performs ridge regression with multiple lambdas.\"\"\"\n",
    "    # split the data, and return train and test data: TODO\n",
    "    train_x, train_y, test_x, test_y = split_data(x, y, ratio, seed)\n",
    "\n",
    "    # form train and test data with polynomial basis function: TODO\n",
    "    train_x_aug = build_poly(train_x, degree)\n",
    "    test_x_aug = build_poly(test_x, degree)\n",
    "\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    \n",
    "    min_w_te = []\n",
    "    min_rmse_te = -1\n",
    "    best_lambda = False\n",
    "    \n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "\n",
    "        # ridge regression with a given lambda        \n",
    "        w = ridge_regression(train_y, train_x_aug, lambda_)\n",
    "        \n",
    "        rmse_tr.append(compute_rmse(train_y, train_x_aug, w))\n",
    "        rmse_te.append(compute_rmse(test_y, test_x_aug, w))\n",
    "        \n",
    "        if rmse_te[ind] < min_rmse_te or min_rmse_te == -1:\n",
    "            min_rmse_te = rmse_te[ind]\n",
    "            min_w_te = w\n",
    "            best_lambda = lambda_\n",
    "        \n",
    "        # ***************************************************\n",
    "#         print(\"proportion={p}, degree={d}, lambda={l:.3f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "#                p=ratio, d=degree, l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))\n",
    "        \n",
    "    # Plot the obtained results\n",
    "    #print(f\"Degree={degree}, ratio={np.round(ratio, 3)}, seed={seed}, min test RMSE={np.round(min_rmse_te, 4)} for lambda={np.round(best_lambda, 7)}\")\n",
    "    plot_train_test(rmse_tr, rmse_te, lambdas, degree)\n",
    "    \n",
    "    return min_rmse_te, min_w_te, best_lambda\n",
    "\n",
    "# THEOTEST code\n",
    "# ridge_regression_demo(x=np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).T, \n",
    "#                       y=np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]).T,\n",
    "#                       degree = 3,\n",
    "#                       ratio = 0.7,\n",
    "#                       seed = 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 137\n",
    "start_degree = 3\n",
    "max_degree = 5\n",
    "start_split_ratio = 0.7\n",
    "end_split_ratio = 0.75\n",
    "split_step = 0.1\n",
    "lambdas = np.logspace(-5, -5, 100)\n",
    "\n",
    "ratio_steps = 10\n",
    "\n",
    "best_best_w = []\n",
    "best_best_rmse = -1\n",
    "best_degree = -1\n",
    "best_best_lambda = False\n",
    "best_ratio = -1\n",
    "best_correctness = -1\n",
    "\n",
    "for degree_i in np.arange(start=(start_degree-1), stop=max_degree):\n",
    "    print(f\"Starting degree {np.round(degree_i+1,2)}\")\n",
    "    for split_ratio in np.arange(start=start_split_ratio, stop=end_split_ratio, step=split_step):\n",
    "        min_rmse_te, min_w_te, best_lambda = ridge_regression_lambdas(no_err_train_x_df.to_numpy(), y, degree_i+1, split_ratio, seed, lambdas)\n",
    "\n",
    "        # Compute values for train data adjusted for -1 and 1 values predicted\n",
    "        train_x_aug_theo = build_poly(no_err_train_x_df.to_numpy(), degree_i+1)\n",
    "        y_out_train = np.dot(train_x_aug_theo, min_w_te)\n",
    "\n",
    "        # Count how many outputs are correctly predicted vs not correctly\n",
    "        y_out_train[y_out_train>=0] = 1\n",
    "        y_out_train[y_out_train<0] = -1\n",
    "        #print(f\"When -1 or 1 RMSE={ np.round(compute_rmse(y_out_train, train_x_aug_theo, min_w_te), 5)}, correctness={100*(y_out_train == y).tolist().count(True)/y_out_train.shape[0]}%\\n\")\n",
    "        correctness = 100*(y_out_train == y).tolist().count(True)/y_out_train.shape[0]\n",
    "\n",
    "        if correctness > best_correctness:\n",
    "            best_best_rmse = min_rmse_te\n",
    "            best_best_w = min_w_te\n",
    "            best_degree = degree_i+1\n",
    "            best_best_lambda = best_lambda\n",
    "            best_correctness = correctness\n",
    "            best_ratio = split_ratio\n",
    "            complete_train_data_rmse = np.round(compute_rmse(y_out_train, train_x_aug_theo, best_best_w), 5)\n",
    "            print(f\"Correctness improved at RMSE={complete_train_data_rmse}, degree={best_degree}, splitratio={np.round(best_ratio, 2)} : correctness={best_correctness}%\\n\")\n",
    "\n",
    "# Compute values for train data adjusted for -1 and 1 values predicted\n",
    "best_best_train_x_aug_theo = build_poly(no_err_train_x_df.to_numpy(), best_degree)\n",
    "best_best_y_out_train = np.dot(best_best_train_x_aug_theo, best_best_w)\n",
    "\n",
    "# Count how many outputs are correctly predicted vs not correctly\n",
    "best_best_y_out_train[best_best_y_out_train>=0] = 1\n",
    "best_best_y_out_train[best_best_y_out_train<0] = -1\n",
    "best_correctness_ratio_prct = 100*(best_best_y_out_train == y).tolist().count(True)/best_best_y_out_train.shape[0]\n",
    "print(f\"\\n Best best values are degree={best_degree}, ratio={best_ratio}, RMSE={best_best_rmse}, lambda={np.round(best_best_lambda, 7)} correctness={best_correctness_ratio_prct}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once some good parameters are found, we will train one last time on the whole dataset (Att : keep same parameters otherwise it doesn't make sense !).\n",
    "Because we are keeping the same lambda an degree, and other parameters, the over/under fitting state of the model should'nt change,\n",
    "but by adding more datapoints it should be more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train one last time but on complete dataset\n",
    "last_train_x_aug = build_poly(no_err_train_x_df.to_numpy(), best_degree)\n",
    "best_last_w = ridge_regression(y, last_train_x_aug, best_best_lambda)\n",
    "\n",
    "#Last check of correctness ratio\n",
    "last_y_train_pred = np.dot(last_train_x_aug, best_last_w)\n",
    "\n",
    "last_y_train_pred[last_y_train_pred>=0] = 1\n",
    "last_y_train_pred[last_y_train_pred<0] = -1\n",
    "print(f\"Correctness ratio for all train data={100*(last_y_train_pred == y).tolist().count(True)/last_y_train_pred.shape[0]}%\")\n",
    "\n",
    "# Compute values for the test set, in order to submit them\n",
    "last_test_x_aug = build_poly(no_err_test_x_df.to_numpy(), best_degree)\n",
    "last_y_test_out = np.dot(last_test_x_aug, best_last_w)\n",
    "\n",
    "last_y_test_out[last_y_test_out>=0] = 1\n",
    "last_y_test_out[last_y_test_out<0] = -1\n",
    "\n",
    "LAST_OUT_NAME = f\"submit_ridge_seed{seed}_deg{degree}.csv\"\n",
    "create_csv_submission(ids_test, last_y_test_out, LAST_OUT_NAME)\n",
    "print(\"Correctly created file with name=\", LAST_OUT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also see what happens when we cross multiply parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions after setting error values to mean of the other column values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkMBGpay4pjh"
   },
   "source": [
    "# Save prediction ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i--OcRst4pjh"
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grQDhIJ84pjk"
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
